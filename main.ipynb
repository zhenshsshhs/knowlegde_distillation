{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from  torchvision.models import resnet18, resnet152\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "parser = argparse.ArgumentParser(description='Knowledge Distillation with ResNet')\n",
    "parser.add_argument('--epochs', type=int, default=30, help='Number of training epochs')\n",
    "parser.add_argument('--batch-size', type=int, default=32, help='Training batch size')\n",
    "parser.add_argument('--temperature', type=float, default=5.0, help='Temperature parameter for knowledge distillation')\n",
    "parser.add_argument('--alpha', type=float, default=0.5, help='Weight for combining soft and hard targets')\n",
    "parser.add_argument('--data-dir', type=str, default='/data1/zhengshuaijie/data', help='Path to the directory containing the dataset')\n",
    "parser.add_argument('--output-dir', type=str, default='/home/zhengshuaijie/repository/knowledge_Distillation/output', help='Path to the directory for saving the model')\n",
    "parser.add_argument('--device', type=str, default='cuda:3', help='Device to use for training (e.g. cpu, cuda)')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = tuple(zip(*batch))\n",
    "    inputs = torch.stack(inputs,dim=0)\n",
    "    masks = []\n",
    "    for annotation in targets:\n",
    "        segmentation = annotation['segmentation']\n",
    "        mask = torch.zeros(annotation['bbox'][3], annotation['bbox'][2], dtype=torch.uint8)\n",
    "        for polygon in segmentation:\n",
    "            polygon = torch.tensor(polygon).view(-1, 2)\n",
    "            polygon[:, 0].clamp_(min=0, max=annotation['bbox'][2]-1)\n",
    "            polygon[:, 1].clamp_(min=0, max=annotation['bbox'][3]-1)\n",
    "            polygon = polygon.round().long()\n",
    "            rr, cc = polygon[:, 1], polygon[:, 0]\n",
    "            mask[rr, cc] = 1\n",
    "        masks.append(mask)\n",
    "\n",
    "\n",
    "    # # 将所有Mask Tensor转换为PyTorch Tensor\n",
    "    # tensor = torch.stack(masks)\n",
    "    targets = torch.stack(masks)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "        return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据变换和加载器\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=22.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CocoDetection(root=os.path.join(args.data_dir,'train2017'), annFile=os.path.join(args.data_dir, 'annotations/instances_train2017.json'), transform=transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4,collate_fn=collate_fn ) #collate_fn=collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3697 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zhengshuaijie/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zhengshuaijie/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_23650/4289077818.py\", line 6, in collate_fn\n    segmentation = annotation['segmentation']\nTypeError: list indices must be integers or slices, not str\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(train_loader)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(targets)\n\u001b[1;32m      5\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1373\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zhengshuaijie/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/zhengshuaijie/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/tmp/ipykernel_23650/4289077818.py\", line 6, in collate_fn\n    segmentation = annotation['segmentation']\nTypeError: list indices must be integers or slices, not str\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(train_loader)\n",
    "for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_dataset = datasets.CocoDetection(root=os.path.join(args.data_dir,'val2017'), annFile=os.path.join(args.data_dir, 'annotations/instances_val2017.json'), transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "\n",
    "# 教师模型和学生模型\n",
    "teacher_model = resnet152(pretrained=True)\n",
    "teacher_model.fc = nn.Linear(2048, len(train_dataset.coco.cats))\n",
    "teacher_model.to(args.device)\n",
    "teacher_model.eval()\n",
    "\n",
    "student_model = resnet18(pretrained=True)\n",
    "student_model.fc = nn.Linear(512, len(train_dataset.coco.cats))\n",
    "student_model.to(args.device)\n",
    "criterion = nn.KLDivLoss().to(args.device)\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# 辅助函数\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = torch.distributions.beta.Beta(alpha, alpha).sample([x.size(0), 1, 1, 1]).to(x.device)\n",
    "        index = torch.randperm(x.size(0)).to(x.device)\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "        return mixed_x, y_a, y_b, lam\n",
    "    else:\n",
    "        return x, y, None, None\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    if lam is not None:\n",
    "        return (lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)).mean()\n",
    "    else:\n",
    "        return criterion(pred, y_a)\n",
    "\n",
    "def label_smooth(target, num_classes, smoothing=0.1):\n",
    "    confidence = 1 - smoothing\n",
    "    label_shape = torch.Size((target.size(0), num_classes))\n",
    "    smoothed_labels = torch.full(size=label_shape, fill_value=smoothing / (num_classes - 1)).to(target.device)\n",
    "    smoothed_labels.scatter_(1, target.unsqueeze(1), confidence)\n",
    "    return smoothed_labels\n",
    "\n",
    "# 训练和测试函数\n",
    "def train(epoch):\n",
    "    student_model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        inputs = inputs.to(args.device)\n",
    "        targets = targets.to(args.device)\n",
    "\n",
    "        mixed_inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, args.alpha)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = student_model(mixed_inputs)\n",
    "        if targets_b is None:\n",
    "            loss = criterion(outputs, label_smooth(targets_a, train_dataset.coco.cats))\n",
    "        else:\n",
    "            soft_targets = torch.softmax(teacher_model(inputs) / args.temperature, dim=1)\n",
    "            soft_targets = soft_targets.detach()\n",
    "            soft_targets = mixup_data(soft_targets, soft_targets[index, :], lam)[0]\n",
    "            soft_targets = label_smooth(soft_targets, train_dataset.coco.cats)\n",
    "            loss = mixup_criterion(criterion, outputs, label_smooth(targets_a, train_dataset.coco.cats), soft_targets, lam)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        pbar.set_description('Epoch: [{}/{}], Loss: {:.4f}, Acc: {:.2f}%'.format(epoch, args.epochs, train_loss / (batch_idx + 1), 100. * correct / total))\n",
    "\n",
    "def test(epoch):\n",
    "    student_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(args.device), targets.to(args.device)\n",
    "            outputs = student_model(inputs)\n",
    "            loss = criterion(outputs, label_smooth(targets, train_dataset.coco.cats))\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            pbar.set_description('Epoch: [{}/{}], Loss: {:.4f}, Acc: {:.2f}%'.format(epoch, args.epochs, test_loss / (batch_idx + 1), 100. * correct / total))\n",
    "    return 100. * correct / total\n",
    "\n",
    "# 训练主函数\n",
    "def main():\n",
    "    best_acc = 0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        start_time = time.time()\n",
    "        train(epoch)\n",
    "        acc = test(epoch)\n",
    "        end_time = time.time()\n",
    "        print('Time taken for epoch {} is {:.2f} seconds'.format(epoch, end_time - start_time))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(student_model.state_dict(), os.path.join(args.output_dir, 'resnet18_best.pth'))\n",
    "    print('Best test accuracy: {:.2f}%'.format(best_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
